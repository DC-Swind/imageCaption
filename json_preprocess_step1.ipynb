{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#预处理一\" data-toc-modified-id=\"预处理一-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>预处理一</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#导入工具包\" data-toc-modified-id=\"导入工具包-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>导入工具包</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#文件路径的确定\" data-toc-modified-id=\"文件路径的确定-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>文件路径的确定</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#数据转换\" data-toc-modified-id=\"数据转换-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>数据转换</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#convert2coco(caption_json,-img_dir)\" data-toc-modified-id=\"convert2coco(caption_json,-img_dir)-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>convert2coco(caption_json, img_dir)</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#convert2coco_val(caption_json,-img_dir)\" data-toc-modified-id=\"convert2coco_val(caption_json,-img_dir)-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>convert2coco_val(caption_json, img_dir)</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#convert2coco_eval(caption_json,-img_dir)\" data-toc-modified-id=\"convert2coco_eval(caption_json,-img_dir)-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>convert2coco_eval(caption_json, img_dir)</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#convert2coco_test(caption_json,-img_dir)\" data-toc-modified-id=\"convert2coco_test(caption_json,-img_dir)-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>convert2coco_test(caption_json, img_dir)</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#数据转换\" data-toc-modified-id=\"数据转换-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>数据转换</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/json_preprocess_step1.ipynb#生成新的训练集\" data-toc-modified-id=\"生成新的训练集-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>生成新的训练集</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理一\n",
    "这是Image_Caption第一个运行的代码，核心功能就是将数据格式进行转换成和coco数据类似的格式,方便后续处理."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from PIL import Image\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径的确定\n",
    "下面这些位置对应的数据全部来自于官方给的数据.(https://challenger.ai/competition/caption/subject),可以自行下载.\n",
    "\n",
    "- train_caption_json: 训练集对应的图片的语句解释（5句话）\n",
    "- train_img_dir: 训练集中图片对应的位置\n",
    "- val_caption_json: 验证集对应的图片的语句解释（5句话）\n",
    "- val_img_dir：验证集中图片对应的位置\n",
    "- test_img_dir: 测试集中图片对应的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_caption_json = '/home/jiangqy/EXP/competition/data/captions/ai_challenger_caption_train_20170902/caption_train_annotations_20170902.json'\n",
    "train_img_dir = '/home/jiangqy/EXP/competition/data/captions/ai_challenger_caption_train_20170902/caption_train_images_20170902'\n",
    "val_caption_json = '/home/jiangqy/EXP/competition/data/captions/ai_challenger_caption_validation_20170910/caption_validation_annotations_20170910.json'\n",
    "val_img_dir = '/home/jiangqy/EXP/competition/data/captions/ai_challenger_caption_validation_20170910/caption_validation_images_20170910'\n",
    "test_img_dir = '/home/jiangqy/EXP/competition/data/captions/ai_challenger_caption_test1_20170923/caption_test1_images_20170923'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据转换\n",
    "**四个函数解释 ** \n",
    "下面的四个函数可以认为是一个函数,都是希望将原始的官方的数据转换成coco的格式,方便后续的训练和测试以及线下的验证.\n",
    "\n",
    "**<font colot = red>此处并不涉及任何图片特征的处理 </font> **\n",
    "\n",
    "- convert2coco(caption_json, img_dir): 将官方给的训练数据转化为coco形式进行存储\n",
    "- convert2coco_val(caption_json, img_dir): 将官方给的验证数据转化为coco形式进行存储\n",
    "- convert2coco_eval(caption_json, img_dir): 将官方给的验证数据转化为coco形式进行存储(主要是为了线下进行BLEU@4的指标等计算)\n",
    "- convert2coco_test(caption_json, img_dir)： 将官方给的测试集数据转化为coco形式进行存储\n",
    "\n",
    "具体的细节可以看下面的每个函数的解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert2coco(caption_json, img_dir)\n",
    "将训练集的图片和文字进行一一对应并进行存储.<br />\n",
    "\n",
    "每一个coco的形式为：<font color =red>['images','annotations']</font> 其中images存储图片的信息,包括图片的位置,图片的长宽,图片的名字以及图片的url等信息，而annotations则存储图片的id以及图片对应的描述性的话.(每张图片有5句描述的话,一张图片对应5句话一起当做一个example进行存储),所以最终coco中['images','annotations']的大小为210000(训练图片的个数).\n",
    "<br />\n",
    "\n",
    "最终的结果存储在目录:<font /color = blue>output_file = os.path.join('./json_preprocess_data', 'coco_'+os.path.basename(caption_json))</font>,可以自行修改位置."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change original form into coco form \n",
    "# save the changed form in out_put_file \n",
    "def convert2coco(caption_json, img_dir):\n",
    "    dataset = json.load(open(caption_json, 'r'))\n",
    "    imgdir = img_dir\n",
    "\n",
    "    coco = dict()\n",
    "    coco[u'info'] = { u'desciption':u'AI challenger image caption in mscoco format'}\n",
    "    coco[u'licenses'] = ['Unknown', 'Unknown']\n",
    "    coco[u'images'] = list()\n",
    "    coco[u'annotations'] = list()\n",
    "\n",
    "    for ind, sample in enumerate(dataset):\n",
    "        img = Image.open(os.path.join(imgdir, sample['image_id']))\n",
    "        width, height = img.size\n",
    "\n",
    "        coco_img = {}\n",
    "        coco_img[u'license'] = 0 #不用管\n",
    "        coco_img[u'file_name'] = os.path.split(img_dir)[-1]+'/'+sample['image_id'] #图片的文件名称\n",
    "        coco_img[u'width'] = width  #图片的宽\n",
    "        coco_img[u'height'] = height #图片的高\n",
    "        coco_img[u'date_captured'] = 0\n",
    "        coco_img[u'coco_url'] = sample['url']  #图片对应的网址，可以输入url找到对应的图片\n",
    "        coco_img[u'flickr_url'] = sample['url'] #图片对应的网址\n",
    "        coco_img['id'] = os.path.splitext(os.path.basename(sample['image_id']))[0] #图片的id,我们用图片的名字作为图片的id\n",
    "\n",
    "        coco_anno = {}\n",
    "        coco_anno[u'image_id'] = os.path.splitext(os.path.basename(sample['image_id']))[0] #图片的id,我们用图片的名字作为图片的id，这个id用来对应图片与文字\n",
    "        coco_anno[u'id'] = os.path.splitext(os.path.basename(sample['image_id']))[0] #图片的id,我们用图片的名字作为图片的id，这个id用来对应图片与文字\n",
    "        coco_anno[u'caption'] = sample['caption'] #图片对应的文字的描述\n",
    "\n",
    "        coco[u'images'].append(coco_img) \n",
    "        coco[u'annotations'].append(coco_anno)\n",
    "        if ind % 1000 == 0:\n",
    "            print('{}/{}'.format(ind, len(dataset)))\n",
    "\n",
    "    output_file = os.path.join('./json_preprocess_data', 'coco_'+os.path.basename(caption_json))  #存储\n",
    "    with open(output_file, 'w') as fid:\n",
    "        json.dump(coco, fid)\n",
    "    print('Saved to {}'.format(output_file))\n",
    "    return coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert2coco_val(caption_json, img_dir)\n",
    "将验证集的图片和文字进行一一对应并进行存储.<br />\n",
    "\n",
    "每一个coco的形式和训练集类似：<font color =red>['images','annotations']</font> 其中images存储图片的信息,包括图片的位置,图片的长宽,图片的名字以及图片的url等信息，而annotations则存储图片的id以及图片对应的描述性的话.(每张图片有5句描述的话),所以最终coco的大小为30000,其中30000为验证图片的个数.和训练集是类似的\n",
    "<br />\n",
    "\n",
    "**注意** <br />\n",
    "中间多了这样一段代码:(总体对后续的处理不影响,因为验证集中每张图片基本也都是5句话,可以认为就是和train一样的处理)\n",
    "<font color=red>该部分很少被运行,主要解决上面那个图中的情况，有些captions中间断开了，为空，那我们就用它上面一句话来补充它形成5句话 </font>\n",
    "<font color =blue>\n",
    "          $  for s in sample['caption']:   \n",
    "            if len(s)==0:   \n",
    "                print(ind,'***********')  \n",
    "                print('error: some caption had no words?')   \n",
    "                print(coco_img[u'file_name'])   \n",
    "                sample['caption'][idx] = sample['caption'][idx-1]   \n",
    "                print(sample['caption'])  \n",
    "                print(len(sample['caption']),len(coco_anno[u'caption']))  \n",
    "                print(ind,'***********')  \n",
    "                #break   \n",
    "            idx = idx+1   \n",
    "        coco[u'images'].append(coco_img) \n",
    "        coco[u'annotations'].append(coco_anno)  $\n",
    "</font><br / >\n",
    "        \n",
    "            \n",
    "\n",
    "最终的结果存储在目录:<font /color = blue>output_file = os.path.join('./json_preprocess_data', 'coco_'+os.path.basename(caption_json))</font>,可以自行修改位置."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures_for_jupyter/example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert2coco_val(caption_json, img_dir):\n",
    "    dataset = json.load(open(caption_json, 'r'))\n",
    "    imgdir = img_dir\n",
    "\n",
    "    coco = dict()\n",
    "    coco[u'info'] = { u'desciption':u'AI challenger image caption in mscoco format'}\n",
    "    coco[u'licenses'] = ['Unknown', 'Unknown']\n",
    "    coco[u'images'] = list()\n",
    "    coco[u'annotations'] = list()\n",
    "\n",
    "    for ind, sample in enumerate(dataset):\n",
    "        img = Image.open(os.path.join(imgdir, sample['image_id']))\n",
    "        width, height = img.size\n",
    "\n",
    "        coco_img = {}\n",
    "        coco_img[u'license'] = 0\n",
    "        coco_img[u'file_name'] = os.path.split(img_dir)[-1]+'/'+sample['image_id']\n",
    "        coco_img[u'width'] = width\n",
    "        coco_img[u'height'] = height\n",
    "        coco_img[u'date_captured'] = 0\n",
    "        coco_img[u'coco_url'] = sample['url']\n",
    "        coco_img[u'flickr_url'] = sample['url']\n",
    "        coco_img['id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "\n",
    "        coco_anno = {}\n",
    "        coco_anno[u'image_id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "        coco_anno[u'id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "        coco_anno[u'caption'] = sample['caption']\n",
    "        idx = 0\n",
    "        for s in sample['caption']:  #该部分很少被运行,主要解决上面那个图中的情况，有些captions中间断开了，为空，那我们就用它上面一句话来补充它形成5句话\n",
    "            if len(s)==0: \n",
    "                print('error: some caption had no words?')\n",
    "                print(coco_img[u'file_name'])\n",
    "                sample['caption'][idx] = sample['caption'][idx-1]\n",
    "                print(sample['caption'])\n",
    "                print(len(sample['caption']),len(coco_anno[u'caption'])) \n",
    "                #break\n",
    "            idx = idx+1\n",
    "        coco[u'images'].append(coco_img)\n",
    "        coco[u'annotations'].append(coco_anno)\n",
    "        if ind % 1000 == 0:\n",
    "            print('{}/{}'.format(ind, len(dataset)))\n",
    "\n",
    "    output_file = os.path.join('./json_preprocess_data', 'coco_'+os.path.basename(caption_json))\n",
    "    with open(output_file, 'w') as fid:\n",
    "        json.dump(coco, fid)\n",
    "    print('Saved to {}'.format(output_file))\n",
    "    return coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert2coco_eval(caption_json, img_dir)\n",
    "该函数主要是为了方便计算线下的一些指标,例如BLEU@4这些指标等,类似于线上的评估.如果不打算进行线下的评估可以不适用该函数.<br />\n",
    "\n",
    "该函数有与convert2coco_val有几个区别,将图片的长宽都设置为了224 $*$ 224的，大体的思路和上面一样,是为了后续线下进行验证准备的数据集,所以前期的训练暂时会用不到. \n",
    "\n",
    "每一个coco的形式和训练集类似：<font color =red>['images','annotations']</font> 其中images存储图片的信息,包括图片的位置,图片的长宽,图片的名字以及图片的url等信息，而annotations则存储图片的id以及图片对应的描述性的话.(每张图片有5句描述的话,这边后面会有5张一样的图片对应5句话),所以最终coco的大小为30000 * 5,其中30000为验证图片的个数.\n",
    "<br />\n",
    "\n",
    "**注意** <br />\n",
    "中间多了这样一段代码:(总体对后续的处理不影响,可以认为就是和train一样的处理)\n",
    "<font color =blue>  \n",
    "\n",
    "            for coco_anno_ in coco_anno['caption']:   \n",
    "            coco_anno_s = {}  \n",
    "            coco_anno_s[u'image_id'] = coco_anno[u'image_id']  \n",
    "            coco_anno_s[u'id'] = coco_anno[u'id']  \n",
    "            w = jieba.cut(coco_anno_.strip(), cut_all=False) \n",
    "            p =\" \".join(w) \n",
    "            coco_anno_ = p \n",
    "            coco_anno_s[u'caption'] = coco_anno_ \n",
    "            coco[u'annotations'].append(coco_anno_s)\n",
    "</font>    \n",
    "最终的结果存储在目录:<font /color = blue>output_file = os.path.join('./json_preprocess_data', 'coco_'+os.path.basename(caption_json))</font>,可以自行修改位置."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert2coco_eval(caption_json, img_dir):\n",
    "    dataset = json.load(open(caption_json, 'r'))\n",
    "    imgdir = img_dir\n",
    "\n",
    "    coco = dict()\n",
    "    coco[u'info'] = { u'desciption':u'AI challenger image caption in mscoco format'}\n",
    "    coco[u'licenses'] = ['Unknown', 'Unknown']\n",
    "    coco[u'images'] = list()\n",
    "    coco[u'annotations'] = list()\n",
    "    coco[u'type'] = u'captions'\n",
    "    for ind, sample in enumerate(dataset):\n",
    "        #img = Image.open(os.path.join(imgdir, sample['image_id']))\n",
    "        #width, height = img.size\n",
    "        width, height = 224, 224\n",
    "\n",
    "        coco_img = {}\n",
    "        coco_img[u'license'] = 0\n",
    "        coco_img[u'file_name'] = os.path.split(img_dir)[-1]+'/'+sample['image_id']\n",
    "        coco_img[u'width'] = width\n",
    "        coco_img[u'height'] = height\n",
    "        coco_img[u'date_captured'] = 0\n",
    "        coco_img[u'coco_url'] = sample['url']\n",
    "        coco_img[u'flickr_url'] = sample['url']\n",
    "        coco_img['id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "\n",
    "        coco_anno = {}\n",
    "        coco_anno[u'image_id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "        coco_anno[u'id'] = os.path.splitext(os.path.basename(sample['image_id']))[0]\n",
    "        coco_anno[u'caption'] = sample['caption']\n",
    "\n",
    "        coco[u'images'].append(coco_img)\n",
    "        \n",
    "        for coco_anno_ in coco_anno['caption']:\n",
    "            coco_anno_s = {}\n",
    "            coco_anno_s[u'image_id'] = coco_anno[u'image_id']\n",
    "            coco_anno_s[u'id'] = coco_anno[u'id']\n",
    "            w = jieba.cut(coco_anno_.strip(), cut_all=False)\n",
    "            p = ' '.join(w)\n",
    "            coco_anno_ = p\n",
    "            coco_anno_s[u'caption'] = coco_anno_\n",
    "            coco[u'annotations'].append(coco_anno_s)\n",
    "        if ind % 1000 == 0:\n",
    "            print('{}/{}'.format(ind, len(dataset)))\n",
    "\n",
    "    output_file = os.path.join('./json_preprocess_data', 'coco_val_'+os.path.basename(caption_json))\n",
    "    with open(output_file, 'w') as fid:\n",
    "        json.dump(coco, fid)\n",
    "    print('Saved to {}'.format(output_file))\n",
    "    return coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert2coco_test(caption_json, img_dir)\n",
    "将测试集的图片的信息进行存储.\n",
    "\n",
    "因为测试集中的图片是没有语句描述的,需要我们进行预测才能得到.所以和训练集以及验证集进行比较会缺少文字描述的内容,只含有<font color =red>['images']</font>内容.\n",
    " \n",
    "最终的结果存储在目录:<font color = red>output_file = os.path.join('./json_preprocess_data', 'ai_challenger_test1.json')</font>,可以自行修改位置."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert2coco_test(img_dir):\n",
    "    coco = dict()\n",
    "    coco[u'info'] = { u'desciption':u'AI challenger image caption in mscoco format'}\n",
    "    coco[u'licenses'] = ['Unknown', 'Unknown']\n",
    "    coco[u'images'] = list()\n",
    "    ind = 0\n",
    "    for im_name in enumerate(os.listdir(img_dir)):\n",
    "        width, height = 224, 224\n",
    "\n",
    "        coco_img = {}\n",
    "        coco_img[u'license'] = 0\n",
    "        coco_img[u'file_name'] = im_name[1]\n",
    "        coco_img[u'width'] = width\n",
    "        coco_img[u'height'] = height\n",
    "        coco_img[u'date_captured'] = 0\n",
    "        coco_img[u'id'] = os.path.splitext(os.path.basename(im_name[1]))[0]\n",
    "        ind = ind + 1\n",
    "        coco[u'images'].append(coco_img)\n",
    "\n",
    "        print('{}/{}'.format(ind, len(os.listdir(img_dir))))\n",
    "\n",
    "    output_file = os.path.join('./json_preprocess_data', 'ai_challenger_test1.json')\n",
    "    with open(output_file, 'w') as fid:\n",
    "        json.dump(coco, fid)\n",
    "    print('Saved to {}'.format(output_file)) \n",
    "    return coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转换\n",
    "有了上面的四个函数,我们将我们的数据直接转换为对应的coco形式即可."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert2coco(train_caption_json, train_img_dir)\n",
    "convert2coco_val(val_caption_json, val_img_dir) \n",
    "convert2coco_test(test_img_dir) \n",
    "convert2coco_eval(val_caption_json, val_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成新的训练集\n",
    "这边我们将训练集和验证集合并放到一起，并用split = 'train' | 'val' 来标记该数据属于训练集还是验证集,此外我们将每个图片对应的5句话进行分词,并把所有的分词结果使用tokens进行存储.最终将结果存在:\n",
    "\n",
    "**<font color =red> output_file = os.path.join('./json_preprocess_data', 'coco_ai_challenger_version1.json')</font>** 下面."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import jieba\n",
    "train = json.load(open('./json_preprocess_data/coco_caption_train_annotations_20170902.json', 'r'))\n",
    "val = json.load(open('./json_preprocess_data/coco_caption_validation_annotations_20170910.json', 'r'))\n",
    "print(val.keys())\n",
    "print(val['info'])\n",
    "print(len(val['images']))\n",
    "print(len(val['annotations']))\n",
    "print(val['images'][0])\n",
    "print(val['annotations'][0])\n",
    "\n",
    "imgs = train['images']+val['images']\n",
    "annots = train['annotations']+val['annotations']\n",
    "\n",
    "itoa = {}\n",
    "for a in annots:\n",
    "    imgid = a['image_id']\n",
    "    if not imgid in itoa: itoa[imgid] = []\n",
    "    itoa[imgid].append(a) \n",
    "    \n",
    "out_json={}\n",
    "out=[]\n",
    "for i, img in enumerate(imgs):\n",
    "    out_im = {}\n",
    "    # coco specific here, they store train/val images separately\n",
    "    split = 'train' if 'train' in img['file_name'] else 'val'\n",
    "    annotsi = itoa[img['id']]\n",
    "    sentid = 0\n",
    "    out_im['cocoid'] = img['id']\n",
    "    out_im['filename'] = os.path.basename(img['file_name'])\n",
    "    if 'val' in img['file_name']:\n",
    "        out_im['filepath'] = 'ai_challenger_caption_validation_20170910/caption_validation_images_20170910' #验证集图片存放的位置\n",
    "    else:\n",
    "        out_im['filepath'] = 'ai_challenger_caption_train_20170902/caption_train_images_20170902' #训练集图片存放的位置\n",
    "    out_s = [] \n",
    "    for a in annotsi: \n",
    "        txt = []\n",
    "        jimg = {}\n",
    "        jimg['imgid'] = img['id']\n",
    "        jimg['raw'] = a   # 原先的5个句子\n",
    "        jimg['sentid'] = img['id']+'_'+str(sentid) \n",
    "        for s in a['caption']:\n",
    "            txt.append(list(jieba.cut(s)))  \n",
    "        jimg['tokens'] = txt #现在5个的句子的token组成的词拼接在一起\n",
    "        jimg['sentids'] = [] \n",
    "        out_s.append(jimg) \n",
    "    out_im['sentences'] = out_s\n",
    "    out_im['split'] = split\n",
    "    out.append(out_im)\n",
    "out_json['images']=out\n",
    "out_json['dataset']='ai_challenger'\n",
    "output_file = os.path.join('./json_preprocess_data', 'coco_ai_challenger_new_version.json')\n",
    "json.dump(out_json, open(output_file, 'w'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "136px",
    "width": "226px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}